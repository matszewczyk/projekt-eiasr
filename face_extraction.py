# -*- coding: utf-8 -*-
"""Face_extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KNxn9_3Ta1yDXd6sCBtpY2lztUUU6Qln
"""

from google.colab import drive
from PIL import Image, ImageOps
import numpy as np
import cv2 
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import os
from matplotlib.patches import Rectangle

drive.mount('/content/drive/')

img = Image.open('/content/drive/MyDrive/EIASR_test_photos/img3.jpg')

display(img)

# Source: https://github.com/kb22/Create-Face-Data-from-Images
prototxt_path = os.path.join('/content/drive/MyDrive/model_data/deploy.prototxt')
caffemodel_path = os.path.join('/content/drive/MyDrive/model_data/weights.caffemodel')
model = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)

image = cv2.imread('/content/drive/MyDrive/EIASR_test_photos/img3.jpg')
(h, w) = image.shape[:2]
blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))
model.setInput(blob)
detections = model.forward()

faces = []
img = np.array(img)
fig,ax = plt.subplots(1)
fig.set_size_inches(16,8)
ax.imshow(img)
count = 0
for i in range(0, detections.shape[2]):
  box = detections[0,0,i,3:7] * np.array([w,h,w,h])
  startX, startY, endX, endY = box.astype("int")
  confidence = detections[0,0,i,2]
  if confidence > 0.5:
    count += 1
    frame = image[startY:endY, startX:endX]
    faces.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

    rect = patches.Rectangle((startX,startY),endX-startX,endY-startY,linewidth=1,edgecolor='r',facecolor='none')
    ax.add_patch(rect)

plt.imshow(faces[4])



